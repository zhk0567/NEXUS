package com.llasm.nexusunified

import android.Manifest
import android.annotation.SuppressLint
import android.app.Activity
import android.content.Context
import android.content.pm.PackageManager
import android.media.AudioManager
import android.os.Bundle
import android.util.Log
import androidx.activity.ComponentActivity
import androidx.activity.compose.setContent
import androidx.compose.foundation.layout.fillMaxSize
import androidx.compose.material3.MaterialTheme
import androidx.compose.material3.Surface
import androidx.compose.runtime.*
import androidx.compose.ui.Modifier
import androidx.compose.ui.platform.LocalContext
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import com.llasm.nexusunified.realtime.RealtimeWebSocketClient
import com.llasm.nexusunified.realtime.RealtimeAudioManager
import com.llasm.nexusunified.service.AIService
import com.llasm.nexusunified.config.ServerConfig
import com.llasm.nexusunified.ui.SettingsManager
import com.llasm.nexusunified.ui.VoiceCallScreen
import com.llasm.nexusunified.ui.ConversationItem
import kotlinx.coroutines.*
import java.util.*
import okhttp3.*
import okhttp3.MediaType.Companion.toMediaType
import okhttp3.RequestBody.Companion.toRequestBody
import org.json.JSONObject

class VoiceCallComposeActivity : ComponentActivity() {
    
    private enum class Role {
        USER,        // ç”¨æˆ·æé—®å†…å®¹
        ASSISTANT,   // åŠ©æ‰‹æœºå™¨äººå›å¤å†…å®¹
        LOG,         // æ—¥å¿—ä¿¡æ¯
    }

    private data class Message(
        val role: Role,
        var text: String,
        var confirmed: Boolean
    )

    companion object {
        private const val TAG = "VoiceCallComposeActivity"
        private const val MAX_DIALOG_MESSAGE_COUNT = 20
        private const val PERMISSION_REQUEST_CODE = 1
        private val DIALOG_PERMISSIONS = arrayOf(Manifest.permission.RECORD_AUDIO)
    }

    // å®æ—¶è¯­éŸ³ç»„ä»¶
    private var webSocketClient: RealtimeWebSocketClient? = null
    private var audioManager: RealtimeAudioManager? = null
    private var aiService: AIService? = null
    
    // çŠ¶æ€ç®¡ç†
    private var isRecording by mutableStateOf(false)
    private var isConnected by mutableStateOf(false)
    private var isWaitingForResponse by mutableStateOf(false)
    private var conversationHistory by mutableStateOf<List<ConversationItem>>(emptyList())
    
    // éŸ³é¢‘å¤„ç†çŠ¶æ€
    private var currentAudioData: ByteArray? = null
    
    // å½•éŸ³æ—¶é—´è®°å½•
    private var recordingStartTime = 0L

    // åç¨‹ä½œç”¨åŸŸ
    private val scope = CoroutineScope(Dispatchers.Main + SupervisorJob())
    
    // HTTPå®¢æˆ·ç«¯ç”¨äºæ•°æ®åº“è®°å½•
    private val httpClient = OkHttpClient.Builder()
        .connectTimeout(10, java.util.concurrent.TimeUnit.SECONDS)
        .readTimeout(30, java.util.concurrent.TimeUnit.SECONDS)
        .writeTimeout(30, java.util.concurrent.TimeUnit.SECONDS)
        .build()
    
    // ä¼šè¯ID
    private val sessionId = "voice_call_${System.currentTimeMillis()}"
    
    // å»é‡æœºåˆ¶
    private val recentUserInputs = mutableSetOf<String>()
    private val recentAIOutputs = mutableSetOf<String>()
    private val maxRecentSize = 10
    
    // é˜²æ­¢é‡å¤è®°å½•çš„æ—¶é—´æˆ³
    private var lastUserInputTime = 0L
    private var lastAIOutputTime = 0L
    private val minIntervalMs = 500L // æœ€å°é—´éš”0.5ç§’ï¼Œé™ä½ä¸¥æ ¼ç¨‹åº¦
    
    // ç´¯ç§¯ç”¨æˆ·è¾“å…¥æ–‡æœ¬ï¼Œé¿å…åˆ†ç‰‡è®°å½•
    private var accumulatedUserInput = ""
    
    // å¯¹è¯é…å¯¹æœºåˆ¶
    private var pendingUserInput: String? = null
    private var pendingAIResponse: String? = null
    private val maxPairingDelayMs = 5000L // æœ€å¤§é…å¯¹å»¶è¿Ÿ5ç§’

    @SuppressLint("ClickableViewAccessibility")
    override fun onCreate(savedInstanceState: Bundle?) {
        Log.i(TAG, "VoiceCallComposeActivity onCreate")
        super.onCreate(savedInstanceState)
        
        // å¼ºåˆ¶ä½¿ç”¨å¤–æ”¾æ‰¬å£°å™¨
        val systemAudioManager = getSystemService(Context.AUDIO_SERVICE) as AudioManager
        systemAudioManager.mode = AudioManager.MODE_NORMAL
        systemAudioManager.isSpeakerphoneOn = true
        systemAudioManager.isBluetoothScoOn = false
        systemAudioManager.isWiredHeadsetOn = false
        
        Log.d(TAG, "onCreate: å·²è®¾ç½®ä½¿ç”¨å¤–æ”¾æ‰¬å£°å™¨")

        initAIService()
        requestPermissions()
        
        setContent {
            val context = LocalContext.current
            val settingsManager = remember { SettingsManager }
            val themeColors = settingsManager.getThemeColors()
            val fontStyle = settingsManager.getFontStyle()
            
            MaterialTheme {
                Surface(
                    modifier = Modifier.fillMaxSize(),
                    color = themeColors.background
                ) {
                   VoiceCallScreen(
                       isConnected = isConnected,
                       isCalling = isRecording, // ä½¿ç”¨ç°æœ‰çš„å½•éŸ³çŠ¶æ€ä½œä¸ºé€šè¯çŠ¶æ€
                       isWaitingForResponse = isWaitingForResponse,
                       conversationHistory = conversationHistory,
                       onHangup = { hangup() },
                       onStartCall = { startRecording() }, // å¼€å§‹å½•éŸ³ä½œä¸ºå¼€å§‹é€šè¯
                       onEndCall = { stopRecording() }, // åœæ­¢å½•éŸ³ä½œä¸ºç»“æŸé€šè¯
                       onSettings = { /* è®¾ç½®åŠŸèƒ½ */ },
                       themeColors = themeColors,
                       fontStyle = fontStyle
                   )
                }
            }
        }
    }
    
    private fun initAIService() {
        try {
            aiService = AIService(this)
            Log.d(TAG, "AIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        } catch (e: Exception) {
            Log.e(TAG, "AIæœåŠ¡åˆå§‹åŒ–å¤±è´¥", e)
        }
    }
    
    
    private fun requestPermissions() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) 
            != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, DIALOG_PERMISSIONS, PERMISSION_REQUEST_CODE)
        } else {
            initializeVoiceComponents()
        }
    }
    
    override fun onRequestPermissionsResult(
        requestCode: Int,
        permissions: Array<out String>,
        grantResults: IntArray
    ) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == PERMISSION_REQUEST_CODE) {
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                initializeVoiceComponents()
            } else {
                Log.e(TAG, "å½•éŸ³æƒé™è¢«æ‹’ç»")
                finish()
            }
        }
    }
    
    private fun initializeVoiceComponents() {
        scope.launch {
            try {
                // åˆå§‹åŒ–WebSocketå®¢æˆ·ç«¯
                webSocketClient = RealtimeWebSocketClient(
                    onMessage = { message -> handleWebSocketMessage(message) },
                    onAudioData = { audioData -> 
                        // æ’­æ”¾AIå›å¤çš„éŸ³é¢‘
                        audioManager?.playAudio(audioData)
                    },
                    onError = { error -> handleWebSocketError(error) },
                    onConnected = { 
                        isConnected = true
                        Log.d(TAG, "WebSocketè¿æ¥æˆåŠŸ")
                    },
                    onDisconnected = { 
                        isConnected = false
                        Log.d(TAG, "WebSocketè¿æ¥æ–­å¼€")
                    },
                    onTranscriptionResult = { text ->
                        // å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœ
                        if (text.isNotEmpty() && text.length > 2) {
                            Log.d(TAG, "ğŸ¤ ç”¨æˆ·: $text")
                            // è®°å½•ç”¨æˆ·è¾“å…¥åˆ°æ•°æ®åº“
                            recordConversation("user", text)
                        }
                    },
                    onTextOutput = { text ->
                        // å¤„ç†AIæ–‡æœ¬è¾“å‡º
                        if (text.isNotEmpty() && text.length > 1) {
                            Log.d(TAG, "ğŸ¤– AI: $text")
                            handleTextResponse(text)
                        }
                    },
                    onResponseComplete = {
                        // AIå“åº”å®Œæˆï¼Œé‡ç½®çŠ¶æ€
                        isWaitingForResponse = false
                        Log.d(TAG, "âœ… AIå“åº”ç»“æŸï¼Œå‡†å¤‡ä¸‹ä¸€è½®å¯¹è¯")
                    },
                    voiceId = "zh_female_vv_jupiter_bigtts" // ä½¿ç”¨é»˜è®¤éŸ³è‰²
                )
                
                // åˆå§‹åŒ–éŸ³é¢‘ç®¡ç†å™¨
                audioManager = RealtimeAudioManager(
                    context = this@VoiceCallComposeActivity,
                    onAudioData = { _ ->
                        // éŸ³é¢‘æ•°æ®å›è°ƒï¼ˆæš‚æ—¶ä¸ä½¿ç”¨ï¼Œæˆ‘ä»¬é€šè¿‡getCurrentAudioDataè·å–ï¼‰
                    },
                    onError = { error -> handleAudioError(error) }
                )
                
                // è¿æ¥WebSocket
                webSocketClient?.connect()
                
            } catch (e: Exception) {
                Log.e(TAG, "åˆå§‹åŒ–è¯­éŸ³ç»„ä»¶å¤±è´¥", e)
            }
        }
    }
    
    private fun handleWebSocketMessage(message: String) {
        scope.launch {
            try {
                // æ£€æŸ¥æ˜¯å¦æ˜¯çº¯æ–‡æœ¬æ¶ˆæ¯ï¼ˆä¸æ˜¯JSONï¼‰
                if (message.startsWith("{") && message.endsWith("}")) {
                    // å°è¯•è§£æJSON
                    val json = JSONObject(message)
                    val type = json.optString("type")
                    
                    when (type) {
                        "audio_response" -> {
                            val audioData = json.optString("audio_data")
                            if (audioData.isNotEmpty()) {
                                playAudioResponse(audioData)
                            }
                        }
                        "text_response" -> {
                            val text = json.optString("text")
                            if (text.isNotEmpty()) {
                                handleTextResponse(text)
                            }
                        }
                        "status" -> {
                            val status = json.optString("status")
                            Log.d(TAG, "æ”¶åˆ°çŠ¶æ€æ›´æ–°: $status")
                        }
                    }
                } else {
                    // å¤„ç†çº¯æ–‡æœ¬æ¶ˆæ¯ï¼ˆå¯èƒ½æ˜¯æ—¥å¿—æˆ–çŠ¶æ€ä¿¡æ¯ï¼‰
                    Log.d(TAG, "æ”¶åˆ°WebSocketæ¶ˆæ¯: $message")
                }
            } catch (e: Exception) {
                // å¦‚æœJSONè§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯çº¯æ–‡æœ¬æ¶ˆæ¯
                Log.d(TAG, "æ”¶åˆ°WebSocketæ¶ˆæ¯: $message")
            }
        }
    }
    
    private fun handleWebSocketError(error: String) {
        Log.e(TAG, "WebSocketé”™è¯¯: $error")
    }
    
    
    private fun handleAudioError(error: String) {
        Log.e(TAG, "éŸ³é¢‘é”™è¯¯: $error")
    }
    
    private fun playAudioResponse(audioData: String) {
        scope.launch {
            try {
                // å°†Base64å­—ç¬¦ä¸²è½¬æ¢ä¸ºByteArray
                val audioBytes = android.util.Base64.decode(audioData, android.util.Base64.DEFAULT)
                audioManager?.playAudio(audioBytes)
            } catch (e: Exception) {
                Log.e(TAG, "æ’­æ”¾éŸ³é¢‘å¤±è´¥", e)
            }
        }
    }
    
    private fun handleTextResponse(text: String) {
        scope.launch {
            try {
                isWaitingForResponse = false
                
                // æ·»åŠ åˆ°å¯¹è¯å†å²
                val newItem = ConversationItem(
                    role = "assistant",
                    text = text,
                    timestamp = System.currentTimeMillis()
                )
                conversationHistory = conversationHistory + newItem
                
                // ä¸è®°å½•AIå›å¤åˆ°æ•°æ®åº“ï¼Œé¿å…åˆ†ç‰‡è®°å½•é—®é¢˜
                Log.d(TAG, "AIå›å¤: $text")
            } catch (e: Exception) {
                Log.e(TAG, "å¤„ç†æ–‡æœ¬å›å¤å¤±è´¥", e)
            }
        }
    }
    
    private fun startRecording() {
        if (isConnected && !isRecording && !isWaitingForResponse) {
            scope.launch {
                try {
                    isRecording = true
                    recordingStartTime = System.currentTimeMillis()
                    audioManager?.startRecording()
                    Log.d(TAG, "å¼€å§‹å½•éŸ³")
                } catch (e: Exception) {
                    Log.e(TAG, "å¼€å§‹å½•éŸ³å¤±è´¥", e)
                    isRecording = false
                }
            }
        }
    }
    
    private fun stopRecording() {
        if (isRecording) {
            scope.launch {
                try {
                    val recordingDuration = System.currentTimeMillis() - recordingStartTime
                    audioManager?.stopRecording()
                    isRecording = false
                    isWaitingForResponse = true
                    
                    // è·å–å½•éŸ³æ•°æ®å¹¶å‘é€
                    val audioData = audioManager?.getCurrentAudioData()
                    if (audioData != null) {
                        sendAudioToAI(audioData)
                    } else {
                        Log.e(TAG, "è·å–å½•éŸ³æ•°æ®å¤±è´¥")
                        isWaitingForResponse = false
                    }
                    
                    Log.d(TAG, "åœæ­¢å½•éŸ³ï¼Œç­‰å¾…AIå›å¤ (å½•éŸ³æ—¶é•¿: ${String.format("%.1f", recordingDuration / 1000.0)} ç§’)")
                } catch (e: Exception) {
                    Log.e(TAG, "åœæ­¢å½•éŸ³å¤±è´¥", e)
                    isRecording = false
                    isWaitingForResponse = false
                }
            }
        }
    }
    
    private fun sendAudioToAI(audioData: ByteArray) {
        scope.launch {
            try {
                // æŒ‰ç…§Pythonä»£ç åˆ†å—å‘é€
                val chunkSize = 3200 // 16000Hz * 0.2ç§’ = 3200å­—èŠ‚
                
                // ç¡®ä¿éŸ³é¢‘æ•°æ®é•¿åº¦æ˜¯chunkSizeçš„æ•´æ•°å€
                val paddingNeeded = (chunkSize - (audioData.size % chunkSize)) % chunkSize
                val paddedAudioData = if (paddingNeeded > 0) {
                    audioData + ByteArray(paddingNeeded) // æ·»åŠ é™éŸ³å¡«å……
                } else {
                    audioData
                }
                
                // å‘é€æ‰€æœ‰éŸ³é¢‘å—
                for (i in 0 until paddedAudioData.size step chunkSize) {
                    val chunk = paddedAudioData.sliceArray(i until i + chunkSize)
                    webSocketClient?.sendAudioData(chunk)
                    delay(10) // å°å»¶è¿Ÿé¿å…å‘é€è¿‡å¿«
                }
                
                // å‘é€é™éŸ³å—ä½œä¸ºç»“æŸæ ‡è®°
                webSocketClient?.sendSilenceChunks()
                
                Log.d(TAG, "ğŸ“¤ è¯­éŸ³å·²å‘é€ï¼Œç­‰å¾…AIå›å¤...")
                
            } catch (e: Exception) {
                Log.e(TAG, "å‘é€è¯­éŸ³å¤±è´¥", e)
                isWaitingForResponse = false
            }
        }
    }
    
    private fun hangup() {
        scope.launch {
            try {
                // åœæ­¢å½•éŸ³å’Œæ’­æ”¾
                audioManager?.stopRecording()
                audioManager?.stopPlayback()
                
                // æ–­å¼€WebSocketè¿æ¥
                webSocketClient?.disconnect()
                
                // é€€å‡ºç”µè¯æ¨¡å¼
                finish()
            } catch (e: Exception) {
                Log.e(TAG, "æŒ‚æ–­å¤±è´¥", e)
                finish()
            }
        }
    }
    
    private fun toggleSubtitle() {
        // å­—å¹•åŠŸèƒ½å®ç°
        Log.d(TAG, "åˆ‡æ¢å­—å¹•æ˜¾ç¤º")
    }
    
    private fun recordConversation(role: String, text: String) {
        scope.launch(Dispatchers.IO) {
            try {
                val currentTime = System.currentTimeMillis()
                
                // é˜²æ­¢é‡å¤è®°å½•
                when (role) {
                    "user" -> {
                        if (currentTime - lastUserInputTime < minIntervalMs) return@launch
                        if (recentUserInputs.contains(text)) return@launch
                        lastUserInputTime = currentTime
                        recentUserInputs.add(text)
                        if (recentUserInputs.size > maxRecentSize) {
                            recentUserInputs.remove(recentUserInputs.first())
                        }
                    }
                    "assistant" -> {
                        if (currentTime - lastAIOutputTime < minIntervalMs) return@launch
                        if (recentAIOutputs.contains(text)) return@launch
                        lastAIOutputTime = currentTime
                        recentAIOutputs.add(text)
                        if (recentAIOutputs.size > maxRecentSize) {
                            recentAIOutputs.remove(recentAIOutputs.first())
                        }
                    }
                }
                
                // è·å–çœŸå®çš„ç”¨æˆ·IDå’Œä¼šè¯ID
                val userId = com.llasm.nexusunified.data.UserManager.getUserId() ?: "android_user_${System.currentTimeMillis()}"
                val sessionId = com.llasm.nexusunified.data.UserManager.getSessionId() ?: "android_session_${System.currentTimeMillis()}"
                
                val requestBody = JSONObject().apply {
                    put("user_id", userId)
                    put("interaction_type", "voice_call")
                    put("content", if (role == "user") text else "")
                    put("response", if (role == "assistant") text else "")
                    put("session_id", sessionId)
                    put("success", true)
                }.toString().toRequestBody("application/json".toMediaType())
                
                val request = Request.Builder()
                    .url(ServerConfig.getApiUrl(ServerConfig.Endpoints.INTERACTIONS_LOG))
                    .post(requestBody)
                    .build()
                
                val response = httpClient.newCall(request).execute()
                if (response.isSuccessful) {
                    Log.d(TAG, "âœ… ç”µè¯æ¨¡å¼å¯¹è¯è®°å½•æˆåŠŸ: $role")
                } else {
                    Log.e(TAG, "âŒ ç”µè¯æ¨¡å¼å¯¹è¯è®°å½•å¤±è´¥: ${response.code}")
                }
                response.close()
                
            } catch (e: Exception) {
                Log.e(TAG, "âŒ è®°å½•å¯¹è¯å¤±è´¥", e)
            }
        }
    }
    
    
    override fun onDestroy() {
        super.onDestroy()
        scope.cancel()
        webSocketClient?.disconnect()
        audioManager?.stopRecording()
        audioManager?.stopPlayback()
    }
}
